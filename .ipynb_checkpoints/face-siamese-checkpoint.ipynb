{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f11e373-8405-4d41-ac9f-f95f0a389520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7c68ea-8a7d-4bef-a9ff-0852d5b00c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder structure\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c6521-291b-4a8d-affa-a7d834211594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69f9c5-1297-4472-a243-3807cea775ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset - https://www.kaggle.com/datasets/jessicali9530/lfw-dataset?resource=download\n",
    "#extracting lfw dataset\n",
    "!tar -xf lfw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5c8a7-b8f9-4720-8e09-577c2153dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move lfw images to data/negative\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84df9897-2584-4fce-969c-9a64ac375e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uuid to generate unique image names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b644c6c0-94d6-4ecd-a254-850a410c0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image capturing for anchors, positives\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #cut down frame to 250x250\n",
    "    frame = frame = frame[120:120+250, 200:200+250, :]\n",
    "\n",
    "    #collect anchors\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "    #collect positives\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17ef2ab-ca54-4890-917f-29641e63d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data paths\n",
    "anchor = [os.path.join(ANC_PATH, f) for f in os.listdir(ANC_PATH) if f.endswith(\".jpg\")][:300]\n",
    "positive = [os.path.join(POS_PATH, f) for f in os.listdir(POS_PATH) if f.endswith(\".jpg\")][:300]\n",
    "negative = [os.path.join(NEG_PATH, f) for f in os.listdir(NEG_PATH) if f.endswith(\".jpg\")][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfda50e9-ab56-492a-838e-b98f5a2feb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def load_and_preprocess(file_path):\n",
    "    img = Image.open(file_path).convert(\"RGB\")\n",
    "    img = preprocess(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2936da98-61f4-4616-a674-64aeb151cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = load_and_preprocess('data\\\\anchor\\\\74e85329-d280-11f0-a34d-80a3977a1ccc.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07534852-3d9a-4eaa-942e-aab5c92df47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5a726a5-4da5-4600-a0f8-5c4bf6a73789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labelled dataset\n",
    "positives = [(a, p, 1) for a, p in zip(anchor, positive)]\n",
    "negatives = [(a, n, 0) for a, n in zip(anchor, negative)]\n",
    "\n",
    "data = positives + negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2ad78c9-2218-4504-80d6-3567cba800df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset\n",
    "random.shuffle(data)\n",
    "\n",
    "split = int(0.8 * len(data))\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c8bf7b9-4494-48e4-91ca-19879be6b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a_path, b_path, label = self.pairs[idx]\n",
    "        img1 = load_and_preprocess(a_path)\n",
    "        img2 = load_and_preprocess(b_path)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "208860ee-aa45-4add-b36e-5e1c81518701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_dataset = SiameseDataset(train_data)\n",
    "val_dataset = SiameseDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "876d3fd6-8c69-4f27-97f8-2f4de5faf3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8fd2a-d5f7-4db4-9e6a-47f2095e6207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
